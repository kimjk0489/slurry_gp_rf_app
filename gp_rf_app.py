import streamlit as st
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_mll
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition.analytic import LogExpectedImprovement
from botorch.optim import optimize_acqf

st.set_page_config(page_title="Slurry Optimization", layout="wide")
st.title("ğŸ”¬ Anode Slurry ì¡°ì„± ìµœì í™” (GP + RF ì•™ìƒë¸”)")

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("slurry_data.csv")
x_cols = ["carbon_black_g", "graphite_g", "CMC_g", "solvent_g"]
y_cols = ["yield_stress"]
X_raw = df[x_cols].values
Y_raw = df[y_cols].values

# ì •ê·œí™”
x_scaler = MinMaxScaler()
X_scaled = x_scaler.fit_transform(X_raw)

# í…ì„œ ë³€í™˜
train_x = torch.tensor(X_scaled, dtype=torch.double)
train_y = torch.tensor(Y_raw, dtype=torch.double)

if st.button("ğŸ” ì¡°ì„± ì¶”ì²œ ë° ì˜ˆì¸¡ ê·¸ë˜í”„ ë³´ê¸°"):

    # GP ëª¨ë¸ í•™ìŠµ
    model = SingleTaskGP(train_x, train_y)
    mll = ExactMarginalLogLikelihood(model.likelihood, model)
    fit_gpytorch_mll(mll)

    # RF ëª¨ë¸ í•™ìŠµ
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_scaled, Y_raw.ravel())

    # íšë“í•¨ìˆ˜ ì •ì˜ (GP ê¸°ì¤€)
    best_y = train_y.max()
    bounds = torch.stack([
        torch.zeros(train_x.shape[1], dtype=torch.double),
        torch.ones(train_x.shape[1], dtype=torch.double)
    ])
    acq_fn = LogExpectedImprovement(model=model, best_f=best_y, maximize=True)

    # ìµœì  ì¡°ì„± íƒìƒ‰
    candidate_scaled, _ = optimize_acqf(
        acq_function=acq_fn,
        bounds=bounds,
        q=1,
        num_restarts=5,
        raw_samples=20
    )
    candidate_np = candidate_scaled.detach().numpy()
    candidate_original = x_scaler.inverse_transform(candidate_np)

    # 4ê°€ì§€ ì¶”ì²œ ì¡°ì„±ê°’ ì¶œë ¥
    st.subheader("ğŸ“Œ ì¶”ì²œëœ ì¡°ì„± (ë‹¨ìœ„: g)")
    for i, col in enumerate(x_cols):
        st.write(f"{col}: **{candidate_original[0][i]:.3f} g**")

    # carbon_blackë§Œ xì¶•ìœ¼ë¡œ ì‹œê°í™”
    x_vals = np.linspace(0, 1, 100)
    carbon_black_index = x_cols.index("carbon_black_g")
    x_test_full = np.tile(np.mean(X_scaled, axis=0), (100, 1))  # í‰ê·  ì¡°ì„± ê³ ì •
    x_test_full[:, carbon_black_index] = x_vals  # carbon_blackë§Œ ë³€í™”ì‹œí‚´

    X_test = torch.tensor(x_test_full, dtype=torch.double)
    model.eval()
    with torch.no_grad():
        pred = model.posterior(X_test)
        gp_mean = pred.mean.numpy().flatten()
        gp_std = pred.variance.sqrt().numpy().flatten()

    rf_mean = rf_model.predict(x_test_full)
    ensemble_mean = 0.5 * gp_mean + 0.5 * rf_mean
    ensemble_upper = ensemble_mean + 1.96 * gp_std
    ensemble_lower = ensemble_mean - 1.96 * gp_std

    x_vals_g = x_scaler.inverse_transform(x_test_full)[:, carbon_black_index]
    train_cb = X_raw[:, carbon_black_index]
    train_y_np = Y_raw.flatten()

    # ê·¸ë˜í”„ ì¶œë ¥
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(x_vals_g, ensemble_mean, color="purple", label="Ensemble Mean (GP + RF)")
    ax.fill_between(x_vals_g, ensemble_lower, ensemble_upper, color="purple", alpha=0.2, label="95% CI (from GP)")
    ax.scatter(train_cb, train_y_np, color="red", label="Observed Data")
    ax.set_title("Prediction vs Carbon Black")
    ax.set_xlabel("Carbon Black [g]")
    ax.set_ylabel("Yield Stress [Pa]")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)
